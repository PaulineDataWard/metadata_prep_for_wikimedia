`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_skip(),
`dc.relation.isreferencedby[en_UK]` = col_skip(),
`dc.relation.isversionof[]` = col_skip(),
`dc.relation.isversionof[en_UK]` = col_skip(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
print("distinct uri values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
print("distinct uri2 values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan
tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block <- read_xls("metadata/pattypan_intermediate_processed_fileset_UK_Tower_Block.xls",
col_types = c("text", "text", "text",
"text", "text", "text", "text"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source_repo_UK_comp_collection <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block %>% mutate(img_filename = basename(path))
# Use stringr to extract filename from title
# No longer need to avoid changing upper case to lower case, as we're using the intermediate fileset '/processed', already lower case.
filtered_tbl_source_repo_UK_comp_collection$img_filename <- ""
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(img_filename = str_replace_all(dc_title, "^.*, ", ""))
# j
# jettison columns no longer needed in filtered_tb_source
filtered_tbl_source_repo_UK_comp_collection <- select(filtered_tbl_source_repo_UK_comp_collection,-dc_contributor,-dc_contributor_other)
# Left join on common column ie img_filename - adds all columns
new_pattypan_metadata <-  new_pattypan_metadata %>%
left_join(filtered_tbl_source_repo_UK_comp_collection, by = "img_filename")
# Combine metadata from source repo and pattypan,
# in preparation for upload of photo collection to Wikimedia Commons
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_skip(),
`dc.contributor[en]` = col_skip(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_skip(),
`dc.relation.isreferencedby[en_UK]` = col_skip(),
`dc.relation.isversionof[]` = col_skip(),
`dc.relation.isversionof[en_UK]` = col_skip(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
print("distinct uri values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
print("distinct uri2 values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan
tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block <- read_xls("metadata/pattypan_intermediate_processed_fileset_UK_Tower_Block.xls",
col_types = c("text", "text", "text",
"text", "text", "text", "text"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source_repo_UK_comp_collection <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block %>% mutate(img_filename = basename(path))
# Use stringr to extract filename from title
# No longer need to avoid changing upper case to lower case, as we're using the intermediate fileset '/processed', already lower case.
filtered_tbl_source_repo_UK_comp_collection$img_filename <- ""
View(filtered_tbl_source_repo_UK_comp_collection)
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>%
mutate(img_filename = str_replace_all(dc_title, "^.*, ", "")) %>%
mutate(dc_coverage_spatial = c(dc_coverage_spatial, dc_coverage_spatial_en, dc_coverage_spatial_en_uk)) %>%
mutate(dc_coverage_temporal = str_sub(dc_coverage_temporal, start = 7, end = 10))
mutate(dc_coverage_spatial = c(as.character(dc_coverage_spatial), as.character(dc_coverage_spatial_en), as.character(dc_coverage_spatial_en_uk)) %>%
# Combine metadata from source repo and pattypan,
# in preparation for upload of photo collection to Wikimedia Commons
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_skip(),
`dc.contributor[en]` = col_skip(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_skip(),
`dc.relation.isreferencedby[en_UK]` = col_skip(),
`dc.relation.isversionof[]` = col_skip(),
`dc.relation.isversionof[en_UK]` = col_skip(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
print("distinct uri values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
print("distinct uri2 values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan
tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block <- read_xls("metadata/pattypan_intermediate_processed_fileset_UK_Tower_Block.xls",
col_types = c("text", "text", "text",
"text", "text", "text", "text"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source_repo_UK_comp_collection <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Prep the columns in order to combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block %>% mutate(img_filename = basename(path))
# Use stringr to extract filename from title
# No longer need to avoid changing upper case to lower case, as we're using the intermediate fileset '/processed', already lower case.
filtered_tbl_source_repo_UK_comp_collection$img_filename <- ""
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>%
mutate(img_filename = str_replace_all(dc_title, "^.*, ", "")) %>%
mutate(dc_coverage_spatial = c(as.character(dc_coverage_spatial), as.character(dc_coverage_spatial_en), as.character(dc_coverage_spatial_en_uk)) %>%
mutate(dc_coverage_temporal = str_sub(dc_coverage_temporal, start = 7, end = 10))
# Combine metadata from source repo and pattypan,
# in preparation for upload of photo collection to Wikimedia Commons
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_skip(),
`dc.contributor[en]` = col_skip(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_skip(),
`dc.relation.isreferencedby[en_UK]` = col_skip(),
`dc.relation.isversionof[]` = col_skip(),
`dc.relation.isversionof[en_UK]` = col_skip(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
print("distinct uri values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
print("distinct uri2 values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan
tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block <- read_xls("metadata/pattypan_intermediate_processed_fileset_UK_Tower_Block.xls",
col_types = c("text", "text", "text",
"text", "text", "text", "text"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Prep the columns in order to combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block %>% mutate(img_filename = basename(path))
# Use stringr to extract filename from title
# No longer need to avoid changing upper case to lower case, as we're using the intermediate fileset '/processed', already lower case.
filtered_tbl_source$img_filename <- ""
filtered_tbl_source <- filtered_tbl_source %>%
mutate(img_filename = str_replace_all(dc_title, "^.*, ", ""))
filtered_tbl_source <- filtered_tbl_source_repo_UK_comp_collection %>%
mutate(dc_coverage_spatial = c(as.character(dc_coverage_spatial), as.character(dc_coverage_spatial_en), as.character(dc_coverage_spatial_en_uk))
filtered_tbl_source <- filtered_tbl_source %>%
filtered_tbl_source$img_filename <- ""
filtered_tbl_source <- filtered_tbl_source %>% mutate(img_filename = str_replace_all(dc_title, "^.*, ", ""))
filtered_tbl_source <- filtered_tbl_source %>% mutate(dc_coverage_spatial = c(dc_coverage_spatial, dc_coverage_spatial_en, dc_coverage_spatial_en_uk))
filtered_tbl_source <- filtered_tbl_source %>% mutate(dc_coverage_spatial = c(as.character(dc_coverage_spatial), dc_coverage_spatial_en, dc_coverage_spatial_en_uk))
filtered_tbl_source <- filtered_tbl_source %>% mutate(dc_coverage_spatial = c(filtered_tbl_source$dc_coverage_spatial, dc_coverage_spatial_en, dc_coverage_spatial_en_uk))
filtered_tbl_source <- filtered_tbl_source %>% mutate(dc_coverage_spatial = paste(filtered_tbl_source$dc_coverage_spatial, dc_coverage_spatial_en, dc_coverage_spatial_en_uk))
View(filtered_tbl_source)
View(filtered_tbl_source)
filtered_tbl_source <- filtered_tbl_source %>% mutate(dc_coverage_temporal = str_sub(dc_coverage_temporal, start = 7, end = 10))
View(filtered_tbl_source)
View(filtered_tbl_source)
View(new_pattypan_metadata)
View(new_pattypan_metadata)
# Combine the three versions of the spatial coverage column - two of the three are always empty 'NA'
filtered_tbl_source <- filtered_tbl_source %>% mutate(dc_coverage_spatial = str_replace(dc_coverage_spatial, "^NA$", ""))
filtered_tbl_source <- filtered_tbl_source %>% mutate(dc_coverage_spatial_en = str_replace(dc_coverage_spatial_en, "^NA$", ""))
filtered_tbl_source <- filtered_tbl_source %>% mutate(dc_coverage_spatial_en_uk = str_replace(dc_coverage_spatial_en_uk, "^NA$", ""))
View(filtered_tbl_source)
View(filtered_tbl_source)
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_skip(),
`dc.contributor[en]` = col_skip(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_skip(),
`dc.relation.isreferencedby[en_UK]` = col_skip(),
`dc.relation.isversionof[]` = col_skip(),
`dc.relation.isversionof[en_UK]` = col_skip(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
print("distinct uri values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
print("distinct uri2 values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan
tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block <- read_xls("metadata/pattypan_intermediate_processed_fileset_UK_Tower_Block.xls",
col_types = c("text", "text", "text",
"text", "text", "text", "text"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Prep the columns in order to combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block %>% mutate(img_filename = basename(path))
# Use stringr to extract filename from title
# No longer need to avoid changing upper case to lower case, as we're using the intermediate fileset '/processed', already lower case.
filtered_tbl_source$img_filename <- ""
filtered_tbl_source <- filtered_tbl_source %>% mutate(img_filename = str_replace_all(dc_title, "^.*, ", ""))
filtered_tbl_source <- filtered_tbl_source %>% mutate(year = str_sub(dc_coverage_temporal, start = 7, end = 10))
filtered_tbl_source <- filtered_tbl_source %>% mutate(depicted_place = coalesce(dc_coverage_spatial, dc_coverage_spatial_en, dc_coverage_spatial_en_uk))
View(filtered_tbl_source)
View(filtered_tbl_source)
# Combine metadata from source repo and pattypan,
# in preparation for upload of photo collection to Wikimedia Commons
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_skip(),
`dc.contributor[en]` = col_skip(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_skip(),
`dc.relation.isreferencedby[en_UK]` = col_skip(),
`dc.relation.isversionof[]` = col_skip(),
`dc.relation.isversionof[en_UK]` = col_skip(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
# print("Imported source metadata is a tibble: ")
# print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
# print("distinct uri values:")
# print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
# print("distinct uri2 values:")
# print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan
tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block <- read_xls("metadata/pattypan_intermediate_processed_fileset_UK_Tower_Block.xls",
col_types = c("text", "text", "text",
"text", "text", "text", "text"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Prep the columns in order to combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block %>% mutate(img_filename = basename(path))
# Use stringr to extract filename from title
# No longer need to avoid changing upper case to lower case, as we're using the intermediate fileset '/processed', already lower case.
filtered_tbl_source$img_filename <- ""
filtered_tbl_source <- filtered_tbl_source %>% mutate(img_filename = str_replace_all(dc_title, "^.*, ", ""))
filtered_tbl_source <- filtered_tbl_source %>% mutate(year = str_sub(dc_coverage_temporal, start = 7, end = 10))
filtered_tbl_source <- filtered_tbl_source %>%
mutate(depicted_place = str_replace(coalesce(dc_coverage_spatial, dc_coverage_spatial_en, dc_coverage_spatial_en_uk)), "||", ", ")
# Combine the three versions of the spatial coverage column - two of the three are always empty 'NA'
filtered_tbl_source <- filtered_tbl_source %>% mutate(depicted_place = str_replace(coalesce(dc_coverage_spatial, dc_coverage_spatial_en, dc_coverage_spatial_en_uk)), "||", ", ")
# Combine the three versions of the spatial coverage column - two of the three are always empty 'NA'
filtered_tbl_source <- filtered_tbl_source %>% mutate(depicted_place = str_replace(coalesce(dc_coverage_spatial, dc_coverage_spatial_en, dc_coverage_spatial_en_uk), "||", ", "))
View(filtered_tbl_source)
View(filtered_tbl_source)
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_skip(),
`dc.contributor[en]` = col_skip(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_skip(),
`dc.relation.isreferencedby[en_UK]` = col_skip(),
`dc.relation.isversionof[]` = col_skip(),
`dc.relation.isversionof[en_UK]` = col_skip(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
# print("Imported source metadata is a tibble: ")
# print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
# print("distinct uri values:")
# print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
# print("distinct uri2 values:")
# print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan
tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block <- read_xls("metadata/pattypan_intermediate_processed_fileset_UK_Tower_Block.xls",
col_types = c("text", "text", "text",
"text", "text", "text", "text"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Prep the columns in order to combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block %>% mutate(img_filename = basename(path))
# Use stringr to extract filename from title
# No longer need to avoid changing upper case to lower case, as we're using the intermediate fileset '/processed', already lower case.
filtered_tbl_source$img_filename <- ""
filtered_tbl_source <- filtered_tbl_source %>% mutate(img_filename = str_replace_all(dc_title, "^.*, ", ""))
filtered_tbl_source <- filtered_tbl_source %>% mutate(year = str_sub(dc_coverage_temporal, start = 7, end = 10))
# Combine the three versions of the spatial coverage column - two of the three are always empty 'NA'
filtered_tbl_source <- filtered_tbl_source %>% mutate(depicted_place = str_replace(coalesce(dc_coverage_spatial, dc_coverage_spatial_en, dc_coverage_spatial_en_uk), "\|\|", ", "))
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_skip(),
`dc.contributor[en]` = col_skip(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_skip(),
`dc.relation.isreferencedby[en_UK]` = col_skip(),
`dc.relation.isversionof[]` = col_skip(),
`dc.relation.isversionof[en_UK]` = col_skip(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
# print("Imported source metadata is a tibble: ")
# print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
# print("distinct uri values:")
# print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
# print("distinct uri2 values:")
# print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan
tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block <- read_xls("metadata/pattypan_intermediate_processed_fileset_UK_Tower_Block.xls",
col_types = c("text", "text", "text",
"text", "text", "text", "text"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Prep the columns in order to combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block %>% mutate(img_filename = basename(path))
# Use stringr to extract filename from title
# No longer need to avoid changing upper case to lower case, as we're using the intermediate fileset '/processed', already lower case.
filtered_tbl_source$img_filename <- ""
filtered_tbl_source <- filtered_tbl_source %>% mutate(img_filename = str_replace_all(dc_title, "^.*, ", ""))
filtered_tbl_source <- filtered_tbl_source %>% mutate(year = str_sub(dc_coverage_temporal, start = 7, end = 10))
# Combine the three versions of the spatial coverage column - two of the three are always empty 'NA'
filtered_tbl_source <- filtered_tbl_source %>% mutate(depicted_place = str_replace(coalesce(dc_coverage_spatial, dc_coverage_spatial_en, dc_coverage_spatial_en_uk), ".*\\|\\|", ", "))
View(filtered_tbl_source)
# Combine metadata from source repo and pattypan,
# in preparation for upload of photo collection to Wikimedia Commons
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_skip(),
`dc.contributor[en]` = col_skip(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_skip(),
`dc.relation.isreferencedby[en_UK]` = col_skip(),
`dc.relation.isversionof[]` = col_skip(),
`dc.relation.isversionof[en_UK]` = col_skip(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
# print("Imported source metadata is a tibble: ")
# print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
# print("distinct uri values:")
# print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
# print("distinct uri2 values:")
# print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan
tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block <- read_xls("metadata/pattypan_intermediate_processed_fileset_UK_Tower_Block.xls",
col_types = c("text", "text", "text",
"text", "text", "text", "text"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Prep the columns in order to combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block %>% mutate(img_filename = basename(path))
# Use stringr to extract filename from title
# No longer need to avoid changing upper case to lower case, as we're using the intermediate fileset '/processed', already lower case.
filtered_tbl_source$img_filename <- ""
filtered_tbl_source <- filtered_tbl_source %>% mutate(img_filename = str_replace_all(dc_title, "^.*, ", ""))
filtered_tbl_source <- filtered_tbl_source %>% mutate(year = str_sub(dc_coverage_temporal, start = 7, end = 10))
filtered_tbl_source <- filtered_tbl_source %>% mutate(depicted_place = coalesce(dc_coverage_spatial, dc_coverage_spatial_en, dc_coverage_spatial_en_uk))
View(filtered_tbl_source)
View(filtered_tbl_source)
filtered_tbl_source <- filtered_tbl_source %>% mutate(depicted_place = str_replace(depicted_place, "||", ""))
View(filtered_tbl_source)
View(filtered_tbl_source)
filtered_tbl_source <- filtered_tbl_source %>% mutate(depicted_place = str_replace(depicted_place, "\|\|", ""))
filtered_tbl_source <- filtered_tbl_source %>% mutate(depicted_place = str_replace(depicted_place, '||', ""))
View(filtered_tbl_source)
View(filtered_tbl_source)
filtered_tbl_source <- filtered_tbl_source %>% mutate(depicted_place = str_replace(depicted_place, '\|\|', ""))
