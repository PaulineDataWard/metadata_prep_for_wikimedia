# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = basename(path))
# Use stringr to extract filename from title
filtered_tbl_source_repo_UK_comp_collection$name <- ""
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace_all("name", "^.*, ", ""))
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace_all(name, "^.*, ", ""))
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace_all(name, ".*,\s", ""))
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace_all(name, ".*, ", ""))
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace(name, ".*, ", ""))
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace(name, ", ", "comma"))
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace(name, ".", "comma"))
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace+all(dc_title, "^.*, ", "comma"))
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace_all(dc_title, "^.*, ", "comma"))
View(filtered_tbl_source_repo_UK_comp_collection)
View(filtered_tbl_source_repo_UK_comp_collection)
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace_all(dc_title, "^.*, ", ""))
View(filtered_tbl_source_repo_UK_comp_collection)
new_pattypan_metadata <-  left_join(filtered_tbl_source_repo_UK_comp_collection, new_pattypan_metadata, by(name))
# Combine metadata from source repo and pattypan,
# in preparation for upload of photo collection to Wikimedia Commons
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_character(),
`dc.contributor[en]` = col_character(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_character(),
`dc.relation.isreferencedby[en_UK]` = col_character(),
`dc.relation.isversionof[]` = col_character(),
`dc.relation.isversionof[en_UK]` = col_character(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
print("distinct uri values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
print("distinct uri2 values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan with readexcel()
tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 <- read_xls("metadata/v1-2_PW_pattypan 2023-05-29 08_10_23.xls",
col_types = c("text", "text", "text",
"text", "text", "skip", "text", "skip",
"skip"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_v1_2_PW_pattypan_2023_05_29_08_10_23))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source_repo_UK_comp_collection <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = basename(path))
View(new_pattypan_metadata)
View(new_pattypan_metadata)
View(tbl_v1_2_PW_pattypan_2023_05_29_08_10_23)
View(tbl_v1_2_PW_pattypan_2023_05_29_08_10_23)
View(filtered_tbl_source_repo_UK_comp_collection)
View(filtered_tbl_source_repo_UK_comp_collection)
# Use stringr to extract filename from title
filtered_tbl_source_repo_UK_comp_collection$name <- ""
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace_all(dc_title, "^.*, ", ""))
View(filtered_tbl_source_repo_UK_comp_collection)
View(filtered_tbl_source_repo_UK_comp_collection)
print(filtered_tbl_source_repo_UK_comp_collection$name %>% filter(str_match(name, "^L" )
)
filtered_tbl_source_repo_UK_comp_collection %>% filter(str_match(name, "^L"))
filtered_tbl_source_repo_UK_comp_collection %>% grepl(name, "^L"))
filtered_tbl_source_repo_UK_comp_collection %>% grepl(name, "^L")
grepl(filtered_tbl_source_repo_UK_comp_collection$name, "^L")
grepl(filtered_tbl_source_repo_UK_comp_collection$name, "^l")
# OUtput to a new file, for pasting into the xls
write_delim(new_pattypan_metadata, here("metadata", "new_pattypan_cols.csv"), delim = ",")
write_delim(filtered_tbl_source_repo_UK_comp_collection, here("metadata", "temp_source_intermediate_file.csv"), delim = ",")
View(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)
View(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)
View(new_pattypan_metadata)
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_character(),
`dc.contributor[en]` = col_character(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_character(),
`dc.relation.isreferencedby[en_UK]` = col_character(),
`dc.relation.isversionof[]` = col_character(),
`dc.relation.isversionof[en_UK]` = col_character(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
print("distinct uri values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
print("distinct uri2 values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan
tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block <- read_xls("metadata/pattypan_intermediate_processed_fileset_UK_Tower_Block.xls",
col_types = c("text", "text", "text",
"text", "text", "text", "text"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block))
View(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block)
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source_repo_UK_comp_collection <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block %>% mutate(name = basename(path))
View(new_pattypan_metadata)
# Use stringr to extract filename from title
# No longer need to avoid changing upper case to lower case, as we're using the intermediate fileset '/processed', already lower case.
filtered_tbl_source_repo_UK_comp_collection$name <- ""
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace_all(dc_title, "^.*, ", ""))
new_pattypan_metadata <-  left_join(filtered_tbl_source_repo_UK_comp_collection, new_pattypan_metadata, by(name))
View(filtered_tbl_source_repo_UK_comp_collection)
# Populate the categories column, in line with the Aberdeen pilot data on Wikimedia Commons
new_pattypan_metadata$categories <- "Public housing in the United Kingdom"
View(new_pattypan_metadata)
# Combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata$img_filename <= ""
# Combine metadata from source repo and pattypan,
# in preparation for upload of photo collection to Wikimedia Commons
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_skip(),
`dc.contributor[en]` = col_skip(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_skip(),
`dc.relation.isreferencedby[en_UK]` = col_skip(),
`dc.relation.isversionof[]` = col_skip(),
`dc.relation.isversionof[en_UK]` = col_skip(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
print("distinct uri values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
print("distinct uri2 values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan
tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block <- read_xls("metadata/pattypan_intermediate_processed_fileset_UK_Tower_Block.xls",
col_types = c("text", "text", "text",
"text", "text", "text", "text"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source_repo_UK_comp_collection <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
View(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block)
View(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block)
# Combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block %>% mutate(img_filename = basename(path))
View(new_pattypan_metadata)
View(new_pattypan_metadata)
# Use stringr to extract filename from title
# No longer need to avoid changing upper case to lower case, as we're using the intermediate fileset '/processed', already lower case.
filtered_tbl_source_repo_UK_comp_collection$img_filename <- ""
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(img_filename = str_replace_all(dc_title, "^.*, ", ""))
View(filtered_tbl_source_repo_UK_comp_collection)
View(filtered_tbl_source_repo_UK_comp_collection)
new_pattypan_metadata <-  left_join(filtered_tbl_source_repo_UK_comp_collection, new_pattypan_metadata, by(img_filename))
new_pattypan_metadata <- left_join(filtered_tbl_source_repo_UK_comp_collection, new_pattypan_metadata, by = img_filename)
new_pattypan_metadata <- left_join(filtered_tbl_source_repo_UK_comp_collection, new_pattypan_metadata)
# Combine metadata from source repo and pattypan,
# in preparation for upload of photo collection to Wikimedia Commons
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_skip(),
`dc.contributor[en]` = col_skip(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_skip(),
`dc.relation.isreferencedby[en_UK]` = col_skip(),
`dc.relation.isversionof[]` = col_skip(),
`dc.relation.isversionof[en_UK]` = col_skip(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
print("distinct uri values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
print("distinct uri2 values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan
tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block <- read_xls("metadata/pattypan_intermediate_processed_fileset_UK_Tower_Block.xls",
col_types = c("text", "text", "text",
"text", "text", "text", "text"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source_repo_UK_comp_collection <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block %>% mutate(img_filename = basename(path))
# Use stringr to extract filename from title
# No longer need to avoid changing upper case to lower case, as we're using the intermediate fileset '/processed', already lower case.
filtered_tbl_source_repo_UK_comp_collection$img_filename <- ""
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(img_filename = str_replace_all(dc_title, "^.*, ", ""))
# Left join implicitly on common column ie img_filename
new_pattypan_metadata <- left_join(filtered_tbl_source_repo_UK_comp_collection, new_pattypan_metadata, by = "img_filename")
View(new_pattypan_metadata)
# Combine metadata from source repo and pattypan,
# in preparation for upload of photo collection to Wikimedia Commons
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_skip(),
`dc.contributor[en]` = col_skip(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_skip(),
`dc.relation.isreferencedby[en_UK]` = col_skip(),
`dc.relation.isversionof[]` = col_skip(),
`dc.relation.isversionof[en_UK]` = col_skip(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
print("distinct uri values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
print("distinct uri2 values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan
tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block <- read_xls("metadata/pattypan_intermediate_processed_fileset_UK_Tower_Block.xls",
col_types = c("text", "text", "text",
"text", "text", "text", "text"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source_repo_UK_comp_collection <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block %>% mutate(img_filename = basename(path))
# Use stringr to extract filename from title
# No longer need to avoid changing upper case to lower case, as we're using the intermediate fileset '/processed', already lower case.
filtered_tbl_source_repo_UK_comp_collection$img_filename <- ""
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(img_filename = str_replace_all(dc_title, "^.*, ", ""))
# j
# jettison columns no longer needed in filtered_tb_source
filtered_tbl_source_repo_UK_comp_collection <- select(filtered_tbl_source_repo_UK_comp_collection,-dc_contributor,-dc_contributor_other)
# Left join on common column ie img_filename - adds all columns
new_pattypan_metadata <-  new_pattypan_metadata %>%
left_join(filtered_tbl_source_repo_UK_comp_collection, by = "img_filename")
# Combine metadata from source repo and pattypan,
# in preparation for upload of photo collection to Wikimedia Commons
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_skip(),
`dc.contributor[en]` = col_skip(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_skip(),
`dc.relation.isreferencedby[en_UK]` = col_skip(),
`dc.relation.isversionof[]` = col_skip(),
`dc.relation.isversionof[en_UK]` = col_skip(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
print("distinct uri values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
print("distinct uri2 values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan
tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block <- read_xls("metadata/pattypan_intermediate_processed_fileset_UK_Tower_Block.xls",
col_types = c("text", "text", "text",
"text", "text", "text", "text"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source_repo_UK_comp_collection <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block %>% mutate(img_filename = basename(path))
# Use stringr to extract filename from title
# No longer need to avoid changing upper case to lower case, as we're using the intermediate fileset '/processed', already lower case.
filtered_tbl_source_repo_UK_comp_collection$img_filename <- ""
View(filtered_tbl_source_repo_UK_comp_collection)
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>%
mutate(img_filename = str_replace_all(dc_title, "^.*, ", "")) %>%
mutate(dc_coverage_spatial = c(dc_coverage_spatial, dc_coverage_spatial_en, dc_coverage_spatial_en_uk)) %>%
mutate(dc_coverage_temporal = str_sub(dc_coverage_temporal, start = 7, end = 10))
mutate(dc_coverage_spatial = c(as.character(dc_coverage_spatial), as.character(dc_coverage_spatial_en), as.character(dc_coverage_spatial_en_uk)) %>%
# Combine metadata from source repo and pattypan,
# in preparation for upload of photo collection to Wikimedia Commons
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_skip(),
`dc.contributor[en]` = col_skip(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_skip(),
`dc.relation.isreferencedby[en_UK]` = col_skip(),
`dc.relation.isversionof[]` = col_skip(),
`dc.relation.isversionof[en_UK]` = col_skip(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
print("distinct uri values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
print("distinct uri2 values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan
tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block <- read_xls("metadata/pattypan_intermediate_processed_fileset_UK_Tower_Block.xls",
col_types = c("text", "text", "text",
"text", "text", "text", "text"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source_repo_UK_comp_collection <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Prep the columns in order to combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block %>% mutate(img_filename = basename(path))
# Use stringr to extract filename from title
# No longer need to avoid changing upper case to lower case, as we're using the intermediate fileset '/processed', already lower case.
filtered_tbl_source_repo_UK_comp_collection$img_filename <- ""
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>%
mutate(img_filename = str_replace_all(dc_title, "^.*, ", "")) %>%
mutate(dc_coverage_spatial = c(as.character(dc_coverage_spatial), as.character(dc_coverage_spatial_en), as.character(dc_coverage_spatial_en_uk)) %>%
mutate(dc_coverage_temporal = str_sub(dc_coverage_temporal, start = 7, end = 10))
# Combine metadata from source repo and pattypan,
# in preparation for upload of photo collection to Wikimedia Commons
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_skip(),
`dc.contributor[en]` = col_skip(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_skip(),
`dc.relation.isreferencedby[en_UK]` = col_skip(),
`dc.relation.isversionof[]` = col_skip(),
`dc.relation.isversionof[en_UK]` = col_skip(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
print("distinct uri values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
print("distinct uri2 values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan
tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block <- read_xls("metadata/pattypan_intermediate_processed_fileset_UK_Tower_Block.xls",
col_types = c("text", "text", "text",
"text", "text", "text", "text"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Prep the columns in order to combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block %>% mutate(img_filename = basename(path))
# Use stringr to extract filename from title
# No longer need to avoid changing upper case to lower case, as we're using the intermediate fileset '/processed', already lower case.
filtered_tbl_source$img_filename <- ""
filtered_tbl_source <- filtered_tbl_source %>%
mutate(img_filename = str_replace_all(dc_title, "^.*, ", ""))
filtered_tbl_source <- filtered_tbl_source_repo_UK_comp_collection %>%
mutate(dc_coverage_spatial = c(as.character(dc_coverage_spatial), as.character(dc_coverage_spatial_en), as.character(dc_coverage_spatial_en_uk))
filtered_tbl_source <- filtered_tbl_source %>%
filtered_tbl_source$img_filename <- ""
filtered_tbl_source <- filtered_tbl_source %>% mutate(img_filename = str_replace_all(dc_title, "^.*, ", ""))
filtered_tbl_source <- filtered_tbl_source %>% mutate(dc_coverage_spatial = c(dc_coverage_spatial, dc_coverage_spatial_en, dc_coverage_spatial_en_uk))
filtered_tbl_source <- filtered_tbl_source %>% mutate(dc_coverage_spatial = c(as.character(dc_coverage_spatial), dc_coverage_spatial_en, dc_coverage_spatial_en_uk))
filtered_tbl_source <- filtered_tbl_source %>% mutate(dc_coverage_spatial = c(filtered_tbl_source$dc_coverage_spatial, dc_coverage_spatial_en, dc_coverage_spatial_en_uk))
filtered_tbl_source <- filtered_tbl_source %>% mutate(dc_coverage_spatial = paste(filtered_tbl_source$dc_coverage_spatial, dc_coverage_spatial_en, dc_coverage_spatial_en_uk))
View(filtered_tbl_source)
View(filtered_tbl_source)
filtered_tbl_source <- filtered_tbl_source %>% mutate(dc_coverage_temporal = str_sub(dc_coverage_temporal, start = 7, end = 10))
View(filtered_tbl_source)
View(filtered_tbl_source)
View(new_pattypan_metadata)
View(new_pattypan_metadata)
# Combine the three versions of the spatial coverage column - two of the three are always empty 'NA'
filtered_tbl_source <- filtered_tbl_source %>% mutate(dc_coverage_spatial = str_replace(dc_coverage_spatial, "^NA$", ""))
filtered_tbl_source <- filtered_tbl_source %>% mutate(dc_coverage_spatial_en = str_replace(dc_coverage_spatial_en, "^NA$", ""))
filtered_tbl_source <- filtered_tbl_source %>% mutate(dc_coverage_spatial_en_uk = str_replace(dc_coverage_spatial_en_uk, "^NA$", ""))
View(filtered_tbl_source)
View(filtered_tbl_source)
