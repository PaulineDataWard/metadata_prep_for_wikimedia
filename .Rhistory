`dc.subject[en_UK]` = col_character(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
# Read in metadata from pattypan with readexcel()
tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 <- read_excel("metadata/v1-2_PW_pattypan 2023-05-29 08_10_23.xls",
col_types = c("text", "text", "text",
"text", "text", "skip", "text", "skip",
"skip"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_v1_2_PW_pattypan_2023_05_29_08_10_23))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source_repo_UK_comp_collection <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Combine by join on the image filename
# Use basename from base R
# something like ... str_replace_all(basename(path), "")???
# filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_sub('.*\\', path))
# tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = str_remove(path, "^.*\\"))
tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = "something-dot-jpeg")
# Combine metadata from source repo and pattypan,
# in preparation for upload of photo collection to Wikimedia Commons
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_character(),
`dc.contributor[en]` = col_character(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_character(),
`dc.relation.isreferencedby[en_UK]` = col_character(),
`dc.relation.isversionof[]` = col_character(),
`dc.relation.isversionof[en_UK]` = col_character(),
`dc.rights[]` = col_character(),
`dc.subject.classification[en_UK]` = col_character(),
`dc.subject[en_UK]` = col_character(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
# Read in metadata from pattypan with readexcel()
tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 <- read_excel("metadata/v1-2_PW_pattypan 2023-05-29 08_10_23.xls",
col_types = c("text", "text", "text",
"text", "text", "skip", "text", "skip",
"skip"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_v1_2_PW_pattypan_2023_05_29_08_10_23))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source_repo_UK_comp_collection <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Combine by join on the image filename
# Use basename from base R
# something like ... str_replace_all(basename(path), "")???
# filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_sub('.*\\', path))
# tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = str_remove(path, "^.*\\"))
tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = path)
# Combine by join on the image filename
# Use basename from base R
# something like ... str_replace_all(basename(path), "")???
# filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_sub('.*\\', path))
# tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = str_remove(path, "^.*\\"))
tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = str_remove_all("\\", path))
# Combine by join on the image filename
# Use basename from base R
# something like ... str_replace_all(basename(path), "")???
# filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_sub('.*\\', path))
# tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = str_remove(path, "^.*\\"))
tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = str_remove_all("^E:.\\\\", path))
# Combine by join on the image filename
# Use basename from base R
# something like ... str_replace_all(basename(path), "")???
# filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_sub('.*\\', path))
# tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = str_remove(path, "^.*\\"))
tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = str_remove_all("^E:.*\\\\", path))
# Combine by join on the image filename
# Use basename from base R
# something like ... str_replace_all(basename(path), "")???
# filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_sub('.*\\', path))
# tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = str_remove(path, "^.*\\"))
tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = str_remove_all("^E:.*\\*", path))
# Combine by join on the image filename
# Use basename from base R
# something like ... str_replace_all(basename(path), "")???
# filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_sub('.*\\', path))
# tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = str_remove(path, "^.*\\"))
tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = str_remove_all(basename(path), path))
library(tools)
# Combine by join on the image filename
# Use basename from base R
# something like ... str_replace_all(basename(path), "")???
# filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_sub('.*\\', path))
# tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = str_remove(path, "^.*\\"))
tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = str_remove_all(basename(path), path))
# Combine by join on the image filename
# Use basename from base R
# something like ... str_replace_all(basename(path), "")???
# filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_sub('.*\\', path))
# tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = str_remove(path, "^.*\\"))
tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = basename(path))
source("C:/coding/projects/metadata_prep_for_wikimedia/wikimedia_pattypan_metadata_prep.R")
View(tbl_v1_2_PW_pattypan_2023_05_29_08_10_23)
source("C:/coding/projects/metadata_prep_for_wikimedia/wikimedia_pattypan_metadata_prep.R")
View(tbl_v1_2_PW_pattypan_2023_05_29_08_10_23)
View(tbl_v1_2_PW_pattypan_2023_05_29_08_10_23)
# Combine by join on the image filename
# Use basename from base R
tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = path)
# Combine by join on the image filename
# Use basename from base R
tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = basename(path))
View(tbl_v1_2_PW_pattypan_2023_05_29_08_10_23)
View(tbl_v1_2_PW_pattypan_2023_05_29_08_10_23)
# Combine by join on the image filename
# Use basename from base R
tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 <- tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = basename(path))
View(tbl_v1_2_PW_pattypan_2023_05_29_08_10_23)
source("C:/coding/projects/metadata_prep_for_wikimedia/wikimedia_pattypan_metadata_prep.R")
source("C:/coding/projects/metadata_prep_for_wikimedia/wikimedia_pattypan_metadata_prep.R")
source("C:/coding/projects/metadata_prep_for_wikimedia/wikimedia_pattypan_metadata_prep.R")
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_character(),
`dc.contributor[en]` = col_character(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_character(),
`dc.relation.isreferencedby[en_UK]` = col_character(),
`dc.relation.isversionof[]` = col_character(),
`dc.relation.isversionof[en_UK]` = col_character(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
summary(tbl_source_repo_raw_export_UK_comp_collecn10283_4857$dc_identifier_uri_2)
select(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857$dc_identifier_uri_2))
print("distinct uri values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857$dc_identifier_uri))
print(distinct(as.character(tbl_source_repo_raw_export_UK_comp_collecn10283_4857$dc_identifier_uri)))
distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857$dc_identifier_uri_2)
distinct(as.character(tbl_source_repo_raw_export_UK_comp_collecn10283_4857$dc_identifier_uri))
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_character(),
`dc.contributor[en]` = col_character(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_character(),
`dc.relation.isreferencedby[en_UK]` = col_character(),
`dc.relation.isversionof[]` = col_character(),
`dc.relation.isversionof[en_UK]` = col_character(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
View(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)
View(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)
View(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)
# Use stringr to extract filename from title
filtered_tbl_source_repo_UK_comp_collection$name <- ""
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source_repo_UK_comp_collection <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Use stringr to extract filename from title
filtered_tbl_source_repo_UK_comp_collection$name <- ""
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_ends("name", "!^.*, "))
View(filtered_tbl_source_repo_UK_comp_collection)
# Combine metadata from source repo and pattypan,
# in preparation for upload of photo collection to Wikimedia Commons
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_character(),
`dc.contributor[en]` = col_character(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_character(),
`dc.relation.isreferencedby[en_UK]` = col_character(),
`dc.relation.isversionof[]` = col_character(),
`dc.relation.isversionof[en_UK]` = col_character(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
print("distinct uri values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
print("distinct uri2 values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan with readexcel()
tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 <- read_xls("metadata/v1-2_PW_pattypan 2023-05-29 08_10_23.xls",
col_types = c("text", "text", "text",
"text", "text", "skip", "text", "skip",
"skip"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_v1_2_PW_pattypan_2023_05_29_08_10_23))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source_repo_UK_comp_collection <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = basename(path))
# Use stringr to extract filename from title
filtered_tbl_source_repo_UK_comp_collection$name <- ""
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace_all("name", "^.*, ", ""))
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace_all(name, "^.*, ", ""))
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace_all(name, ".*,\s", ""))
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace_all(name, ".*, ", ""))
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace(name, ".*, ", ""))
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace(name, ", ", "comma"))
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace(name, ".", "comma"))
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace+all(dc_title, "^.*, ", "comma"))
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace_all(dc_title, "^.*, ", "comma"))
View(filtered_tbl_source_repo_UK_comp_collection)
View(filtered_tbl_source_repo_UK_comp_collection)
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace_all(dc_title, "^.*, ", ""))
View(filtered_tbl_source_repo_UK_comp_collection)
new_pattypan_metadata <-  left_join(filtered_tbl_source_repo_UK_comp_collection, new_pattypan_metadata, by(name))
# Combine metadata from source repo and pattypan,
# in preparation for upload of photo collection to Wikimedia Commons
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_character(),
`dc.contributor[en]` = col_character(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_character(),
`dc.relation.isreferencedby[en_UK]` = col_character(),
`dc.relation.isversionof[]` = col_character(),
`dc.relation.isversionof[en_UK]` = col_character(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
print("distinct uri values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
print("distinct uri2 values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan with readexcel()
tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 <- read_xls("metadata/v1-2_PW_pattypan 2023-05-29 08_10_23.xls",
col_types = c("text", "text", "text",
"text", "text", "skip", "text", "skip",
"skip"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_v1_2_PW_pattypan_2023_05_29_08_10_23))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source_repo_UK_comp_collection <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_v1_2_PW_pattypan_2023_05_29_08_10_23 %>% mutate(name = basename(path))
View(new_pattypan_metadata)
View(new_pattypan_metadata)
View(tbl_v1_2_PW_pattypan_2023_05_29_08_10_23)
View(tbl_v1_2_PW_pattypan_2023_05_29_08_10_23)
View(filtered_tbl_source_repo_UK_comp_collection)
View(filtered_tbl_source_repo_UK_comp_collection)
# Use stringr to extract filename from title
filtered_tbl_source_repo_UK_comp_collection$name <- ""
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace_all(dc_title, "^.*, ", ""))
View(filtered_tbl_source_repo_UK_comp_collection)
View(filtered_tbl_source_repo_UK_comp_collection)
print(filtered_tbl_source_repo_UK_comp_collection$name %>% filter(str_match(name, "^L" )
)
filtered_tbl_source_repo_UK_comp_collection %>% filter(str_match(name, "^L"))
filtered_tbl_source_repo_UK_comp_collection %>% grepl(name, "^L"))
filtered_tbl_source_repo_UK_comp_collection %>% grepl(name, "^L")
grepl(filtered_tbl_source_repo_UK_comp_collection$name, "^L")
grepl(filtered_tbl_source_repo_UK_comp_collection$name, "^l")
# OUtput to a new file, for pasting into the xls
write_delim(new_pattypan_metadata, here("metadata", "new_pattypan_cols.csv"), delim = ",")
write_delim(filtered_tbl_source_repo_UK_comp_collection, here("metadata", "temp_source_intermediate_file.csv"), delim = ",")
View(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)
View(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)
View(new_pattypan_metadata)
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_character(),
`dc.contributor[en]` = col_character(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_character(),
`dc.relation.isreferencedby[en_UK]` = col_character(),
`dc.relation.isversionof[]` = col_character(),
`dc.relation.isversionof[en_UK]` = col_character(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
print("distinct uri values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
print("distinct uri2 values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan
tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block <- read_xls("metadata/pattypan_intermediate_processed_fileset_UK_Tower_Block.xls",
col_types = c("text", "text", "text",
"text", "text", "text", "text"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block))
View(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block)
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source_repo_UK_comp_collection <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block %>% mutate(name = basename(path))
View(new_pattypan_metadata)
# Use stringr to extract filename from title
# No longer need to avoid changing upper case to lower case, as we're using the intermediate fileset '/processed', already lower case.
filtered_tbl_source_repo_UK_comp_collection$name <- ""
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(name = str_replace_all(dc_title, "^.*, ", ""))
new_pattypan_metadata <-  left_join(filtered_tbl_source_repo_UK_comp_collection, new_pattypan_metadata, by(name))
View(filtered_tbl_source_repo_UK_comp_collection)
# Populate the categories column, in line with the Aberdeen pilot data on Wikimedia Commons
new_pattypan_metadata$categories <- "Public housing in the United Kingdom"
View(new_pattypan_metadata)
# Combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata$img_filename <= ""
# Combine metadata from source repo and pattypan,
# in preparation for upload of photo collection to Wikimedia Commons
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_skip(),
`dc.contributor[en]` = col_skip(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_skip(),
`dc.relation.isreferencedby[en_UK]` = col_skip(),
`dc.relation.isversionof[]` = col_skip(),
`dc.relation.isversionof[en_UK]` = col_skip(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
print("distinct uri values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
print("distinct uri2 values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan
tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block <- read_xls("metadata/pattypan_intermediate_processed_fileset_UK_Tower_Block.xls",
col_types = c("text", "text", "text",
"text", "text", "text", "text"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source_repo_UK_comp_collection <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
View(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block)
View(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block)
# Combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block %>% mutate(img_filename = basename(path))
View(new_pattypan_metadata)
View(new_pattypan_metadata)
# Use stringr to extract filename from title
# No longer need to avoid changing upper case to lower case, as we're using the intermediate fileset '/processed', already lower case.
filtered_tbl_source_repo_UK_comp_collection$img_filename <- ""
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(img_filename = str_replace_all(dc_title, "^.*, ", ""))
View(filtered_tbl_source_repo_UK_comp_collection)
View(filtered_tbl_source_repo_UK_comp_collection)
new_pattypan_metadata <-  left_join(filtered_tbl_source_repo_UK_comp_collection, new_pattypan_metadata, by(img_filename))
new_pattypan_metadata <- left_join(filtered_tbl_source_repo_UK_comp_collection, new_pattypan_metadata, by = img_filename)
new_pattypan_metadata <- left_join(filtered_tbl_source_repo_UK_comp_collection, new_pattypan_metadata)
# Combine metadata from source repo and pattypan,
# in preparation for upload of photo collection to Wikimedia Commons
library(tidyverse)
library(here)
library(readr)
library(janitor)
library(readxl)
library(stringr)
library(tools)
# Read in metadata from source repo CSV
# df_datashare_metadata <- read_csv(here("metadata", "source_repo_raw_export_UK_comp_collecn10283-4857.csv"))
tbl_source_repo_raw_export_UK_comp_collecn10283_4857 <- read_csv("metadata/source_repo_raw_export_UK_comp_collecn10283-4857.csv",
col_types = cols(`dc.contributor.other[en_UK]` = col_skip(),
`dc.contributor[en]` = col_skip(),
`dc.coverage.spatial[en]` = col_character(),
`dc.coverage.spatial[en_UK]` = col_character(),
`dc.description.abstract[en_UK]` = col_character(),
`dc.identifier.uri[]` = col_character(),
`dc.language.iso[]` = col_skip(),
`dc.language.iso[en_UK]` = col_skip(),
`dc.publisher[en_UK]` = col_skip(),
`dc.relation.isreferencedby[en_UK]` = col_skip(),
`dc.relation.isversionof[]` = col_skip(),
`dc.relation.isversionof[en_UK]` = col_skip(),
`dc.rights[]` = col_skip(),
`dc.subject.classification[en_UK]` = col_skip(),
`dc.subject[en_UK]` = col_skip(),
`dc.title[en_UK]` = col_character(),
`dc.type[]` = col_skip(), `dc.type[en_UK]` = col_skip(),
`ds.not-emailable.item[en]` = col_skip())) %>% clean_names()
print("Imported source metadata is a tibble: ")
print(as.character(is_tibble(tbl_source_repo_raw_export_UK_comp_collecn10283_4857)))
print("distinct uri values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri))
print("distinct uri2 values:")
print(distinct(tbl_source_repo_raw_export_UK_comp_collecn10283_4857, dc_identifier_uri_2))
# Read in metadata from pattypan
tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block <- read_xls("metadata/pattypan_intermediate_processed_fileset_UK_Tower_Block.xls",
col_types = c("text", "text", "text",
"text", "text", "text", "text"))
print("Imported pattypan table is typeof: ")
print(typeof(tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block))
# Identify and then exclude the images already on wikimedia ie Aberdeen collection
filtered_tbl_source_repo_UK_comp_collection <- tbl_source_repo_raw_export_UK_comp_collecn10283_4857 %>%
filter(! str_detect(collection, "3304"))
# Combine by join on the image filename
# Use basename from base R to extract filename from path
new_pattypan_metadata <- tbl_pattypan_intermediate_processed_fileset_UK_Tower_Block %>% mutate(img_filename = basename(path))
# Use stringr to extract filename from title
# No longer need to avoid changing upper case to lower case, as we're using the intermediate fileset '/processed', already lower case.
filtered_tbl_source_repo_UK_comp_collection$img_filename <- ""
filtered_tbl_source_repo_UK_comp_collection <- filtered_tbl_source_repo_UK_comp_collection %>% mutate(img_filename = str_replace_all(dc_title, "^.*, ", ""))
# Left join implicitly on common column ie img_filename
new_pattypan_metadata <- left_join(filtered_tbl_source_repo_UK_comp_collection, new_pattypan_metadata, by = "img_filename")
View(new_pattypan_metadata)
